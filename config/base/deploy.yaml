# ==============================================================================
# 部署核心配置（含LMDeploy部署参数与模型合并参数，适配推理部署场景）
# 说明：LMDeploy参数用于高效部署推理，合并参数用于模型权重整合（如LoRA合并）
# ==============================================================================

# ==============================================================================
# LMDeploy 部署参数（适配LMDeploy推理框架，参数含义参考LMDeploy官方文档）
# 启用场景：swift deploy 命令，支持多卡并行、量化优化、多模态部署
# ==============================================================================

lmdeploy_tp: 1  # 张量并行（TP）度（多卡部署时调整，控制模型分片策略）
                # 默认值：1

lmdeploy_session_len: null  # 最大会话长度（单轮对话支持的最大token数）
                            # 默认值：null（自动从模型config.json读取）

lmdeploy_cache_max_entry_count: 0.8  # KV缓存占用的GPU内存百分比（0~1之间）
                                     # 用途：平衡缓存大小与推理并发量
                                     # 默认值：0.8

lmdeploy_quant_policy: 0  # KV缓存量化策略
                          # 可选值：0（不量化）、4（KV缓存4位量化）、8（KV缓存8位量化）
                          # 默认值：0

lmdeploy_vision_batch_size: 1  # 视觉模块最大批处理大小（多模态模型专用）
                               # 说明：传入VisionConfig的max_batch_size参数
                               # 默认值：1

# ==============================================================================
# 模型合并参数（用于部署前整合模型权重，如LoRA与底座模型合并）
# ==============================================================================

merge_lora: false  # 是否合并LoRA权重到底座模型
                   # 支持类型：lora、llamapro、longlora
                   # 示例参考：https://swift.readthedocs.io/zh-cn/latest/Examples/MergeLoRA.html
                   # 默认值：false

safe_serialization: true  # 是否使用safetensors格式存储合并后的模型
                          # 优势：安全（避免pickle风险）、高效（加载速度快）
                          # 默认值：true

max_shard_size: "5GB"  # 单文件最大分片大小（合并后模型权重分片存储）
                       # 格式：支持"GB"|"MB"（如"10GB"、"2048MB"）
                       # 用途：避免单个权重文件过大，便于存储和传输
                       # 默认值："5GB"