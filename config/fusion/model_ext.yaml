# ==============================================================================
# 特定模型专属参数配置（适配多模态模型，控制图像/视频/音频处理逻辑，避免训练OOM）
# 引入 base 通用键：模型/数据/生成/引擎等
imports:
    - ./core.yaml
# 说明：
# 1. 参数通过--model_kwargs（JSON字符串）或环境变量设置（如--model_kwargs '{"FPS_MAX_FRAMES": 12}' 或 FPS_MAX_FRAMES=12）
# 2. 训练与推理需保持参数一致，确保效果对齐
# 3. 不同模型族参数独立，未使用的模型族参数可忽略
# ==============================================================================

# ==============================================================================
# Qwen系列多模态模型（qwen2_vl, qvq, qwen2_5_vl, mimo_vl, keye_vl, keye_vl_1_5）
# 参数含义参考：qwen_vl_utils<0.0.12 或 qwen_omni_utils 库（https://github.com/QwenLM/Qwen-VL）
# 核心用途：控制图像/视频分辨率、抽帧数，适配显存大小
# ==============================================================================
qwen_vl_like:
  IMAGE_FACTOR: 28  # 图像缩放因子（建议保持默认，与模型预处理逻辑对齐）
  MIN_PIXELS: 4 * 28 * 28  # 图像最小分辨率（28*28的倍数，确保预处理兼容）
  MAX_PIXELS: 16384 * 28 * 28  # 图像最大分辨率（关键参数，需根据显存调整，避免OOM）
  MAX_RATIO: 200  # 图像宽高比上限（防止极端比例图像导致处理异常）
  VIDEO_MIN_PIXELS: 128 * 28 * 28  # 视频单帧最小分辨率（28*28的倍数）
  VIDEO_MAX_PIXELS: 768 * 28 * 28  # 视频单帧最大分辨率（关键参数，控制单帧显存占用）
  VIDEO_TOTAL_PIXELS: 24576 * 28 * 28  # 视频总像素上限（多帧累计，避免整体OOM）
  FRAME_FACTOR: 2  # 视频帧缩放因子
  FPS: 2.0  # 视频抽帧帧率（每秒抽取的帧数）
  FPS_MIN_FRAMES: 4  # 视频最小抽帧数（确保视频内容完整性）
  FPS_MAX_FRAMES: 768  # 视频最大抽帧数（关键参数，减少长视频显存占用）
  QWENVL_BBOX_FORMAT: "legacy"  # Grounding格式（ms-swift>=3.9.1支持）
                                # 可选值：
                                # - "legacy"：<|object_ref_start|>物体<|object_ref_end|><|box_start|>(x1,y1),(x2,y2)<|box_end|>
                                # - "new"：参考Qwen3-VL cookbook（https://github.com/QwenLM/Qwen-VL/blob/main/cookbook/grounding.md）
                                # 适配模型：Qwen2/2.5/3-VL、Qwen2.5/3-Omni系列

# ==============================================================================
# Qwen2-Audio 模型
# 核心用途：控制音频采样率，确保音频预处理与模型对齐
# ==============================================================================
qwen2_audio:
  SAMPLING_RATE: 16000  # 音频采样率（默认16kHz，与模型训练数据一致）

# ==============================================================================
# Qwen2.5-Omni / Qwen3-Omni 模型
# 继承：qwen2_5_vl + qwen2_audio 的所有参数，新增音频相关控制
# ==============================================================================
qwen_omni:
  USE_AUDIO_IN_VIDEO: false  # 是否使用视频中的音频信息（关闭可降低显存占用）
  ENABLE_AUDIO_OUTPUT: null  # 是否启用音频输出头（关键参数）
                             # 自动逻辑：null时使用config.json默认值
                             # 注意：Zero3训练时建议设为false；仅微调thinker部分时设为false（减少显存占用）

# ==============================================================================
# Qwen3-VL 模型
# 参数含义参考：qwen_vl_utils>=0.0.14 库（https://github.com/QwenLM/Qwen-VL）
# 核心用途：通过token数控制图像/视频处理规模，适配高分辨率场景
# ==============================================================================
qwen3_vl:
  SPATIAL_MERGE_SIZE: 2  # 空间合并尺寸（控制图像token合并逻辑）
  IMAGE_MIN_TOKEN_NUM: 4  # 图像最小token数（单张图片的最小处理粒度）
  IMAGE_MAX_TOKEN_NUM: 16384  # 图像最大token数（关键参数，避免OOM，等价像素=token数*32*32）
  VIDEO_MIN_TOKEN_NUM: 128  # 视频单帧最小token数
  VIDEO_MAX_TOKEN_NUM: 768  # 视频单帧最大token数（关键参数，控制单帧显存占用）
  MAX_RATIO: 200  # 图像/视频宽高比上限
  FRAME_FACTOR: 2  # 视频帧缩放因子
  FPS: 2.0  # 视频抽帧帧率
  FPS_MIN_FRAMES: 4  # 视频最小抽帧数
  FPS_MAX_FRAMES: 768  # 视频最大抽帧数（关键参数，减少长视频处理压力）

# ==============================================================================
# InternVL 系列模型（internvl, internvl_phi3）
# 参数含义参考：https://github.com/OpenGVLab/InternVL
# 核心用途：控制输入图像尺寸与最大处理数量
# ==============================================================================
internvl:
  MAX_NUM: 12  # 最大处理图像数量（单轮对话支持的图片数）
  INPUT_SIZE: 448  # 图像输入尺寸（模型期望的统一分辨率）

# ==============================================================================
# InternVL2+ 系列模型（internvl2, internvl2_phi3, internvl2_5, internvl3, internvl3_5）
# 继承：internvl 的所有参数，新增视频处理配置
# ==============================================================================
internvl2_plus:
  MAX_NUM: 12  # 最大处理图像数量
  INPUT_SIZE: 448  # 图像输入尺寸
  VIDEO_MAX_NUM: 1  # 最大处理视频数量（单轮对话支持的视频数）
  VIDEO_SEGMENTS: 8  # 视频分段数（控制长视频处理粒度）

# ==============================================================================
# MiniCPM 系列模型（minicpmv2_6, minicpmo2_6, minicpmv4）
# 参数含义参考：https://github.com/OpenBMB/MiniCPM
# 核心用途：控制图像切片数、视频抽帧数
# ==============================================================================
minicpm:
  MAX_SLICE_NUMS: 9  # 图像最大切片数（高分辨率图像拆分处理）
  VIDEO_MAX_SLICE_NUMS: 1  # 视频最大切片数
  MAX_NUM_FRAMES: 64  # 视频最大抽帧数（控制视频处理规模）

# ==============================================================================
# MiniCPM-O2.6 模型
# 新增音频相关初始化控制
# ==============================================================================
minicpmo2_6:
  INIT_TTS: false  # 是否初始化TTS（语音合成）模块
  INIT_AUDIO: false  # 是否初始化音频理解模块

# ==============================================================================
# OVIS 系列模型（ovis1_6, ovis2）
# 参数含义参考：https://github.com/OpenGVLab/OVIS
# 核心用途：控制图像分区数
# ==============================================================================
ovis:
  MAX_PARTITION: 9  # 图像最大分区数（高分辨率图像拆分处理）

# ==============================================================================
# OVIS2.5 模型
# 参数含义参考：https://github.com/OpenGVLab/OVIS/blob/main/examples/inference.py
# 核心用途：控制图像/视频分辨率、抽帧数
# ==============================================================================
ovis2_5:
  MIX_PIXELS: 448 * 448  # 混合分辨率基准（图像预处理参考）
  MAX_PIXELS: 1344 * 1792  # 图像最大分辨率（OOM时可调小）
  VIDEO_MAX_PIXELS: 896 * 896  # 视频单帧最大分辨率
  NUM_FRAMES: 8  # 视频抽帧数（固定处理帧数）

# ==============================================================================
# MPlug-Owl3 模型（mplug_owl3, mplug_owl3_241101）
# 参数含义参考：https://github.com/X-PLUG/mplug-owl
# 核心用途：控制视频抽帧数
# ==============================================================================
mplug_owl3:
  MAX_NUM_FRAMES: 16  # 视频最大抽帧数

# ==============================================================================
# XComposer2-4KHD 模型
# 参数含义参考：https://github.com/microsoft/XComposer
# 核心用途：控制高清图像处理参数
# ==============================================================================
xcomposer2_4khd:
  HD_NUM: 55  # 高清图像处理参数（与模型高清预处理逻辑对齐）

# ==============================================================================
# XComposer2.5 模型
# 动态调整高清处理参数（根据图像数量）
# ==============================================================================
xcomposer2_5:
  HD_NUM: null  # 高清图像处理参数
                # 自动逻辑：图片数量=1时默认24，图片数量>1时默认6

# ==============================================================================
# Video-CogVLm2 模型
# 参数含义参考：https://github.com/THUDM/Video-CogVLM
# 核心用途：控制视频抽帧数
# ==============================================================================
video_cogvlm2:
  NUM_FRAMES: 24  # 视频抽帧数

# ==============================================================================
# Phi3-Vision 模型
# 参数含义参考：https://github.com/microsoft/phi-3-mini
# 核心用途：控制图像裁剪数
# ==============================================================================
phi3_vision:
  NUM_CROPS: 4  # 图像裁剪数（多裁剪提升图像理解精度）

# ==============================================================================
# Llama3.1-Omni 模型
# 参数含义参考：https://github.com/meta-llama/llama-recipes
# 核心用途：控制音频梅尔频谱维度
# ==============================================================================
llama3_1_omni:
  N_MELS: 128  # 音频梅尔频谱维度（与模型音频处理头对齐）

# ==============================================================================
# Video-LLaVA 模型
# 核心用途：控制视频抽帧数
# ==============================================================================
video_llava:
  NUM_FRAMES: 16  # 视频抽帧数